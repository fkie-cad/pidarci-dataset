# PIdARCI - Compiler Idioms Dataset
This repository contains the dataset we used to evaluate our PIdARCI approach to detect, annotate, and revert compiler idioms.

You can find our paper introducing the PIdARCI approach [here](https://pstnet.ca).
Furthermore, we published our prototypical implementation [here](https://github.com/fkie-cad/pidarci).

## How is this dataset structured
In general, this dataset contains samples for the following high-level expressions which will oftentimes lead to the use of compiler idioms:
- integer division (signed/unsigned) by a constant
- integer modulo (signed/unsigned) by a constant
- integer multiplication (signed/unsigned) by a constant

For each operation, there is a source code file in `src/`, like e.g. `src/mulu_0_2048.c`.
The source code files contain functions like e.g. the following (for every constant value in the range `(0,2048)` for unsigned operations and `[-1024,1024)` for signed operations):
```
unsigned int func_1(unsigned int num) {
    unsigned int res;
    res = num* (1);
    return res;
}
```
After compiling those source files, the resulting binary functions should contain compiler idiom instruction sequences, in case the given compiler utilizes such.
Hence, the resulting binaries can be used to evaluate compiler idiom matching.

The directory `bin/` contains binary files corresponding to each source code file that have been compiled with the following settings:
* Compilers:
  - GCC 11.2
  - MSVC 19.29
* Architectures `x86/x64`
* Optimization Levels `O0-O3` (for MSVC we used `Od,O1,O2,Ox` respectively)

For binary files generated by MSVC, we also included the respective `.pdb` file to allow inferring the function names.
Also, we include the address ranges for every function of each MSVC-Sample in `bin/__function-info`.

Finally, we include example scripts that show how this dataset can be used to evaluate the compiler idioms handling of a decompiler or PIdARCI.
To evaluate a decompiler, you will need files containing all decompiled functions of each sample in this dataset.
**It should be mentioned that the scripts have been modified to work on the customized output we obtained from each decompiler. To use the for evaluation, they all will need to be adapted.**

While during our experiments, we did not observe any additional instruction patterns for greater ranges, the dataset can, of course, be easily altered to include additional constant values.

## How to use the dataset

**It should be noted that the dataset only contains functions implementing said high-level calculations and not any additional functionalities. As a consequence, depending on your approach it may have to be extended in order to adequately evaluate true negatives.**

Basically, there are two possible usecases where this data-set can be used to evaluate compiler idiom matching:
* **Decompilers**: In case you want to evaluate the compiler idiom handling of a given decompiler, you have to decompile all binaries first. Make sure to include the `.pdb` files for PE files to allow the decompiler using the original function names. Then, you can use a script similar to `evaluate_decompiler.py` to parse the decompilers output for all original functions and high-level calculations. If the decompiler output contains the expected high-level calculation instead of low-level operations like shifts, it was apparently able to correctly handle the given idiom.
* **Approaches like PIdARCI**: In contrast to evaluating decompilers, we don't need to generate source code to decide whether we were able to handle a compiler idiom. Instead, use the approach to match idioms and make sure all relevant functions have been marked correctly.

## How to reference this dataset
Please use the following citation referring to our paper when referencing this dataset:
```
@inproceedings{enders2021pidarci,
  title={PIdARCI: Using Assembly Instruction Patterns to Identify, Annotate, and Revert Compiler Idioms},
  author={Steffen Enders and Mariia Rybalka and Elmar Padilla},
  booktitle={2021 18th International Conference on Privacy, Security and Trust (PST)},
  year={2021},
  organization={IEEE}
}
```
